{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Error Mitigation\n",
    "\n",
    "This notebook contains theoretical background and examples for using our Error Mitigation module with Qiskit. \n",
    "We recommend to first read our [Quantum Detector Tomography Tutorial](QDT_Tutorial.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Theoretical background\n",
    "Here we describe main theoretical concepts related to mitigation procedure. This description is based on Ref. [[1]](https://quantum-journal.org/papers/q-2020-04-24-257/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classical noise model\n",
    "\n",
    "Let us denote by $\\mathbf{M}$ a POVM describing noisy detector and $\\mathbf{P}$ denote ideal measurement. In classical\n",
    "noise model, we assume that the relation between the two is given by stochastic, invertible map $\\Lambda$:\n",
    "\n",
    "$$ \\mathbf{M} = \\Lambda \\mathbf{P}.$$\n",
    "\n",
    "Let us denote by $\\mathbf{p}_{exp}$ vector of probabilities obtained on a noisy detector $\\mathbf{M}$ measuring any\n",
    "quantum state, and by $\\mathbf{p_{ideal}}$ the analogous vector for ideal detector (for the same quantum state). From\n",
    "linearity of the Born's rule, it follows that two vectors are related by the same stochastic map as POVMs:\n",
    "\n",
    "$$ \\mathbf{p_{exp}} = \\Lambda \\mathbf{p_{ideal}}. $$\n",
    "\n",
    "Recall that we assumed that $\\Lambda$ is invertible. Hence by multiplying last equation by $\\Lambda^{-1}$ from both\n",
    "sides, we obtain\n",
    "\n",
    "$$ \\Lambda^{-1} \\mathbf{p_{exp}} = \\mathbf{p_{ideal}}. $$\n",
    "\n",
    "Effectively, by this kind of post-processing, we obtain statistics which we would have obtained on the perfect detector\n",
    "devices."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deviations from noise model\n",
    "\n",
    "There are several ways in which real noise can deviate from our model. Here we will show the way how to handle them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Effects  on mitigation\n",
    "Above we assumed a very specific noise model. In practice it is likely that it will not be fulfilled exactly. In such a\n",
    "scenario, we may perform the following decomposition of POVM $M$ describing our device:\n",
    "$$ \\mathbf{M} = \\Lambda \\mathbf{P} + \\mathbf{\\Delta}\\ ,$$\n",
    "where $\\Delta$ denotes a \"coherent\" part of the noise and $\\Lambda$, as previously, is some stochastic, invertible map. \n",
    "\n",
    "In such a case, we can relate probability vector obtained on the noisy detector to ideal one in manner similar as before\n",
    "\n",
    "$$ \\mathbf{p_{exp}} = \\Lambda \\mathbf{p_{ideal}} + \\mathbf{d}\\ , $$\n",
    "where $\\mathbf{d}$ denotes a disturbance of probability vector due to existence of coherent part of the noise.\n",
    "If we now multiply the above expression by inverse of the noise matrix, we obtain\n",
    "\n",
    "$$ \\Lambda^{-1} \\mathbf{p_{exp}} = \\mathbf{p_{ideal}} + \\Lambda^{-1} \\mathbf{d}, \\  $$\n",
    "\n",
    "\n",
    "This clearly does not leave us with ideal statistics $\\mathbf{p_{ideal}}$, but consists of additional deviation term\n",
    "$\\Lambda^{-1} \\mathbf{d}$ which appears due to non-classicity of noise. Fortunately, this does not preclude our\n",
    "mitigation from working! The correction clearly will not be perfect in this case, however if deviation is sufficiently\n",
    "small, it still might be better then performing no correction at all.\n",
    "\n",
    "We can upper-bound the TV distance of corrected probability distribution from the ideal one by expression\n",
    "$$\n",
    "D_{TV}\\left( \\Lambda^{-1} \\mathbf{p_{exp}},\\mathbf{p_{ideal}} \\right) \\leq ||\\Lambda^{-1}||_{1 \\to 1}\n",
    "D_{op}(\\mathbf{M}, \\Lambda \\mathbf{P}) \\,\n",
    "$$\n",
    "where the $1\\rightarrow 1$ norm is defined as\n",
    "$$\n",
    "||A||_{1\\rightarrow1} = \\sup_{||v||_1} ||Av||_1 \\ .\n",
    "$$\n",
    "\n",
    "It is easy to see that if the detector $\\mathbf{M}$ is related to $\\mathbf{P}$ via only classical noise $\\Lambda$, then\n",
    "the above expression yields $0$, hence the mitigation works perfectly. In the presence of coherent measurement noise,\n",
    "term $D_{op}(\\mathbf{M}, \\Lambda \\mathbf{P})$ may be regarded as a measure of non-classicity of the noise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### How to choose decomposition?\n",
    "\n",
    "In general, we can always perform decomposition into \"classical\" and \"coherent\" part in infinitely many ways. However,\n",
    "for the ideal detector $P$ modeled as projective measurement in computational basis, there exists a perfectly natural\n",
    "ansatz. Namely, we propose to consider diagonal parts of POVM's $\\mathbf{M}$ elements to describe classical part of the\n",
    "noise. As a justification for such choice, note that elements of $\\mathbf{P}$ for such ideal detector model are\n",
    "diagonal, and the stochastic map would preserve the diagonality.\n",
    "\n",
    "Hence, after obtaining description of POVM $\\mathbf{M}$ from detector tomography, reconstruction of $\\Lambda$ can be\n",
    "achieved by taking only diagonal parts of POVM's elements."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finite-size statistics\n",
    "#### Statistical noise\n",
    "So far we have assumed that we have access to actual (noisy) probability distribution $\\mathbf{p_{exp}}$. However, in\n",
    "real life what we can get is only an estimator of this distribution\n",
    "\n",
    "$$ \\mathbf{p_{exp}} \\xrightarrow[\\text{}]{\\text{finite-size sampling}} \\mathbf{p}_{\\mathbf{exp}}^{\\text{est}}\\ ,$$ \n",
    "which simply consists of experimental frequencies of occurrences of particular outcomes.\n",
    "\n",
    "As a result, we will have some statistical noise in our estimator, which we can write as\n",
    "$$\n",
    "\\mathbf{p}_{\\mathbf{exp}}^{\\text{est}}  = \\mathbf{p}_{\\mathbf{exp}} + \\mathbf{s} \\ ,\n",
    "$$\n",
    "where $\\mathbf{s}$ is some vector of statistical deviations. \n",
    "\n",
    "Let us assume that we perform $n$-outcome measurement and gather $k$ samples (shots). Then the magnitude of those\n",
    "statistical deviations can be upper bound by\n",
    "$$\n",
    "D_{TV}\\left(\\mathbf{p}_{\\mathbf{exp}}^{\\text{est}} ,\n",
    "\\mathbf{p}_{\\mathbf{exp}} \\right) \\leq \\sqrt{\\frac{\\log{\\left(2^n-2\\right)}-\\log{\\text{Pr}_{wrong}}}{2k}}\n",
    "\\equiv \\epsilon \\ .\n",
    "$$\n",
    "Bounds on statistical deviations are usually probabilistic, and in the above equation we choose parameter\n",
    "$\\text{Pr}_{wrong}$ such that\n",
    "$$\n",
    "1-\\text{Pr}_{wrong} = \\text{Pr}\\left(D_{TV}\\left(\\mathbf{p}_{\\mathbf{exp}}^{\\text{est}} ,\n",
    "\\mathbf{p}_{\\mathbf{exp}} \\right) \\leq \\epsilon\\right) \\ .\n",
    "$$\n",
    "\n",
    "#### Effects on mitigation\n",
    "Now we want to determine how far (in TV distance) is our corrected estimated statistics vector\n",
    "$\\Lambda^{-1}\\mathbf{p}_{\\mathbf{exp}}^{\\text{est}}$ from ideal statistics $\\mathbf{p_{ideal}}$.\n",
    "This distance can be upper bounded by\n",
    "\n",
    "$$ D_{TV}\\left(\\Lambda^{-1} \\mathbf{p}_{\\mathbf{exp}}^{\\text{est}}, \\mathbf{p_{ideal}}\\right) \\leq\n",
    "\\underbrace{||\\Lambda^{-1}||_{1 \\to 1} D_{op}(\\mathbf{M}, \\Lambda \\mathbf{P})}_{\\text{coherent noise}} +\n",
    "\\underbrace{||\\Lambda^{-1}||_{1 \\to 1} \\epsilon}_{\\text{statistical noise}} =: \\delta. $$\n",
    "\n",
    "This sum consists of two parts. \n",
    "First quantifies propagation of coherent errors under our correction and is the same as in previous subsection.\n",
    "The second term quantifies propagation of statistical noise. For more details see Ref. [[1]](https://quantum-journal.org/papers/q-2020-04-24-257/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quasiprobability vectors\n",
    "In the discussion above we have ignored a very important feature of correction matrix $\\Lambda^{-1}$. Namely, since it is an inverse of stochastic matrix, its columns are in fact quasiprobability vectors - it means that they still sum up to 1, but can be negative. Matrices which such columns in general do not preserve probability vectors - hence left-multiplication of estimated frequencies by $\\Lambda^{-1}$ may sometimes yield a quasiprobability vector! \n",
    "\n",
    "Possible way of dealing with this is to simply find a closest (in some norm) probability vector. In other words, if $\\Lambda^{-1} \\mathbf{p}_{\\mathbf{exp}}^{\\text{est}}$  turns out to be quasiprobability vector, we solve\n",
    "$$\n",
    "\\min_{\\forall_i p_i\\geq 0,\\ \\sum_i p_i =1} ||\\Lambda^{-1} \\mathbf{p}_{\\mathbf{exp}}^{\\text{est}} - \\mathbf{p}||_2 \\ ,\n",
    "$$\n",
    "where we minimize Euclidean distance, not TV distance, because it is easy to solve. \n",
    "\n",
    "Let us denote by $\\mathbf{p_{final}}$ the solution of the above optimization problem. In such a case, we can upper bound possible distance from ideal distribution by\n",
    "$$\n",
    "D_{TV}\\left(\\mathbf{p_{final}}, \\mathbf{p_{ideal}}\\right) \\leq  \\underbrace{\\delta}_{\\text{coherent and statistical noise}} + \\underbrace{\\alpha}_{\\text{\"unphysicality noise\"}} \\ ,\n",
    "$$\n",
    "where by $\\alpha$ we have denoted\n",
    "$$\n",
    "\\alpha := D_{TV}\\left(\\mathbf{p_{final}}, \\Lambda^{-1} \\mathbf{p}_{\\mathbf{exp}}^{\\text{est}}\\right) \\ ,\n",
    "$$\n",
    "hence a distance between initially estimated quasiprobability vector and the solution of optimization problem.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### When is mitigation successful?\n",
    "\n",
    "We have discussed two sources of errors that can worsen results of our mitigation procedure. \n",
    "Since in real-life experiments we do not have access to the ideal probability distribution, it is  impossible to know whether the mitigation was successful. To deal with this, we use the following heuristic rule to assess whether mitigation was successful \n",
    "\n",
    "$$ \\delta + \\alpha < D_{op}(\\mathbf{M}, \\mathbf{P}) + \\epsilon\\ ,$$\n",
    "\n",
    "where $\\delta$ coherent and statistical errors in mitigation,0 $\\alpha$ describes the distance described in previous subsection, and $\\epsilon$ is statistical error.\n",
    "In words - if a possible error introduced by mitigation is lower than the upper bound on error appearing in a detector without mitigation, we consider mitigation successful.\n",
    "\n",
    "Here we back it up by the following arguments. First, we know that at least for some set of quantum states the above is true - namely, the states in the neighborhood of the state that saturates upper bound on the RHS of the above inequality (i.e., states which are \"worst case scenarios\" for noisy detector, recall definition of operational distance from [QDT tutorial](https://github.com/fbm2718/QREM/blob/master/QDT_Tutorial.ipynb)). \n",
    "\n",
    "Secondly, In Appendix B of Ref. [[1]](https://quantum-journal.org/papers/q-2020-04-24-257/) are results of numerical simulations for single and two-qubit (uncorrelated) detectors which confirm that in the case when the above inequality is fulfilled, the majority of noisy probability vectors (generated by random quantum states and noisy detector) indeed come closer to the ideal distribution than if one does not apply mitigation. \n",
    "\n",
    "Finally, in experimental section of Ref. [[1]](https://quantum-journal.org/papers/q-2020-04-24-257/) there is empirical confirmation of the procedure to work for the number of benchmark procedures (note that if we know ideal probability distribution, we clearly can assess whether mitigation has been successful - we also do such tests in practical part of this tutorial).\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mitigating the errors using our module\n",
    "\n",
    "In this section we will describe how to use our mitigation module. We will begin with showing general approach as to\n",
    "how to prepare the mitigator object and then, on several examples, we will show how to use it\n",
    "(on single and multi-qubit circuit results)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performing Quantum Detector Tomography\n",
    "Our error mitigation approach is based on the knowledge about the noise in the device's detector. Such knowledge can be\n",
    "obtained in procedure known as Quantum Detector Tomography (QDT). To perform QDT, one can follow the steps from our\n",
    "[QDT tutorial](https://github.com/fbm2718/QREM/blob/master/QDT_Tutorial.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import povmtools\n",
    "import ancillary_functions as anf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.options.display.float_format = '{:,.3f}'.format\n",
    "\n",
    "from qiskit import IBMQ, Aer, execute\n",
    "from qiskit.providers.aer import noise\n",
    "\n",
    "from quantum_tomography_qiskit import detector_tomography_circuits\n",
    "from DetectorTomography import DetectorTomographyFitter, QDTCalibrationSetup\n",
    "from QDTErrorMitigator import QDTErrorMitigator\n",
    "\n",
    "# Choose qubit indices\n",
    "QDT_qubit_index = [3]\n",
    "\n",
    "# Select probe kets\n",
    "QDT_probe_kets = povmtools.pauli_probe_eigenkets\n",
    "\n",
    "# Generate circuits\n",
    "QDT_circuits = detector_tomography_circuits(QDT_qubit_index, QDT_probe_kets)\n",
    "\n",
    "# Get QDT circuits results\n",
    "backend = Aer.get_backend('qasm_simulator')  #  Get backed\n",
    "shots_number = 8192*20  # Define number of measurement repetitions\n",
    "QDT_job = execute(QDT_circuits, backend=backend, shots=shots_number)\n",
    "results = QDT_job.result()\n",
    "\n",
    "# Get ml_povm_estimator using DTF and results\n",
    "DTF = DetectorTomographyFitter()\n",
    "calibration_setup = QDTCalibrationSetup.from_qiskit_results([results], QDT_probe_kets)\n",
    "ml_povm_estimator = DTF.get_maximum_likelihood_povm_estimator(calibration_setup)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is important to note that in order to increase the tomography precision, one should use as many shots as possible. In this tutorial, we will implement QDTs with a lot of samples (8192$*$20), but experiments we correct will be implemented by smaller number of samples (8192)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing mitigation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the estimator of POVM, we can create QDTErrorMitigator object and prepare it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creation and preparation of QDTErrorMitigator\n",
    "mitigator = QDTErrorMitigator()\n",
    "mitigator.prepare_mitigator(ml_povm_estimator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With prepared mitigator object we gain access to several useful functionalities. For example, we can:\n",
    "* Correct selected statistics (given as numpy ndarray) using apply_correction_to_statistics methd.\n",
    "* Correct results of qiskit job by using apply_correction_to_qiskit_job method.\n",
    "* Access error and correction matrices obtained from POVM given during preparation.\n",
    "\n",
    "In order to properly analyze the results of correction procedure, one needs to recall that in some cases raw\n",
    "application of $\\Lambda^{-1}$ to the results may yield quasi-probability (instead of probability) vectors (see theoretical background). In such\n",
    "scenario our code finds closest probability vectors and returns them instead. Distances from raw quasi-probabilities to\n",
    "returned probabilities, can be accessed via distances_from_closest_probability_vector member of mitigator object."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Error bounds calculation\n",
    "\n",
    "With access to POVM and the error and correction matrices, we are able to calculate bounds on several errors. In\n",
    "particular, using povmtools module, we can calculate:\n",
    "\n",
    "* noisy detector errors - using povmtools.operational_distance function (denoted as $D_{op}\\left(\\mathbf{M},\n",
    "\\mathbf{P}\\right)$ in theoretical background)\n",
    "* statistical error bound - using get_statistical_error_bound method (denoted as $\\epsilon$ in theoretical background),\n",
    "* coherent error bound - using gt_coherent_error_bound method (denoted as $D_{op}\\left(\\mathbf{M},\\Lambda\n",
    "\\mathbf{P}\\right)$ in theoretical background),\n",
    "* correction error bound - using get_correction_error_bound_from_data or get_correction_error_bound_from_parameters\n",
    " method (denoted as $\\delta+\\alpha$ in theoretical background).\n",
    "\n",
    "And later after applying mitigation to particular results we can also calculate\n",
    "* \"unphysicality error\" - using distances_from_closest_probability_vector method (denoted as $\\alpha$ in theoretical\n",
    " background)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single qubit error mitigation\n",
    "\n",
    "In this section we will consider two examples of mitigation for single qubit experiments. First, we will need to create a noisy backend simulator. We start with required imports."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qiskit import QuantumCircuit, ClassicalRegister, QuantumRegister\n",
    "from qiskit import execute\n",
    "from qiskit import IBMQ, Aer\n",
    "from qiskit.providers.aer.noise import NoiseModel\n",
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "\n",
    "import povmtools\n",
    "from DetectorTomography import DetectorTomographyFitter, QDTCalibrationSetup\n",
    "from quantum_tomography_qiskit import detector_tomography_circuits\n",
    "from QDTErrorMitigator import QDTErrorMitigator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use standard qiskit methods to create noisy backend simulator. For this tutorial we will create simulator of IBM's\n",
    "Burlington device which is usually quite noisy. Importantly, here the assumed model is classical and uncorrelated, hence all errors in mitigation will be due to statistical noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  What we want to have first is working noisy backend simulation. In order to do that, we use qiskit noise model\n",
    "# and download properties of selected backend.\n",
    "\n",
    "# Build noise model from backend properties.\n",
    "provider = IBMQ.load_account()\n",
    "backend = provider.get_backend('ibmq_burlington')\n",
    "noise_model = NoiseModel.from_backend(backend)\n",
    "\n",
    "# Get coupling map from backend, why not.\n",
    "coupling_map = backend.configuration().coupling_map\n",
    "\n",
    "# Get basis gates from noise model.\n",
    "basis_gates = noise_model.basis_gates\n",
    "\n",
    "# Finally, get the simulator backend.\n",
    "simulator_backend = Aer.get_backend('qasm_simulator')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With backend created, what we need to do next is to reconstruct the POVM that corresponds to the detector. Following our QDT tutorial, we use DetectorTomographyFitter object from our module. First, we need to create calibration\n",
    "circuits and implement them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.93 0.07]\n",
      "[0.038 0.962]\n",
      "[0.483 0.517]\n",
      "[0.484 0.516]\n",
      "[0.484 0.516]\n",
      "[0.483 0.517]\n"
     ]
    }
   ],
   "source": [
    "# What I want to do now, is prepare POVM for simulated backend. According to our other notebook, I prepare\n",
    "# circuits first.\n",
    "\n",
    "qdt_qubit_index = [0]\n",
    "qdt_probe_kets = povmtools.pauli_probe_eigenkets\n",
    "qdt_calibration_circuits = detector_tomography_circuits(qdt_qubit_index, qdt_probe_kets)\n",
    "\n",
    "# I then execute them on backend prepared earlier.\n",
    "shots_number = 8192*20\n",
    "\n",
    "# Perform a noisy simulation\n",
    "result = execute(qdt_calibration_circuits, simulator_backend, coupling_map=coupling_map, basis_gates=basis_gates,\n",
    "                 noise_model=noise_model, shots=shots_number)\\\n",
    "                 .result()\n",
    "\n",
    "# Print counts.\n",
    "for i in range(len(result.results)):\n",
    "    counts_now = result.get_counts(i)\n",
    "    frequencies_now = povmtools.counts_dict_to_frequencies_vector(counts_now)\n",
    "    print(np.round(frequencies_now,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We note that it is highly preferable to use as high number of shots as possible to minimize statistical errors.  \n",
    "\n",
    "Maximum likelihood POVM calculation is as easy as calling single method now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              0             1\n",
      "0  0.930-0.000j -0.001-0.000j\n",
      "1 -0.001+0.000j  0.038-0.000j\n",
      "             0            1\n",
      "0 0.070+0.000j 0.001+0.000j\n",
      "1 0.001-0.000j 0.962-0.000j\n"
     ]
    }
   ],
   "source": [
    "# With circuits results we can now use our Detector Tomography Fitter to obtain maximum likelihood POVM estimator.\n",
    "dtf = DetectorTomographyFitter()\n",
    "calibration_setup = QDTCalibrationSetup.from_qiskit_results([result], qdt_probe_kets)\n",
    "ml_povm_estimator = dtf.get_maximum_likelihood_povm_estimator(calibration_setup)\n",
    "\n",
    "for m_i in ml_povm_estimator:\n",
    "    nice_looking_m_i = pd.DataFrame(m_i)\n",
    "    print(nice_looking_m_i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that despite classical noise model, reconstructed POVM has small non-diagonal elements. This is the result of the presence of statistical noise. If we have implemented the detector tomography on the actual device, the off-diagonal elements could be result of coherent noise in the device, and should be incorporated into error bars for mitigation (see theoretical background). Here we will omit them.\n",
    "\n",
    "With POVM calculated, we can now create and prepare mitigator object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can use obtained POVM to correct to prepare mitigation object.\n",
    "mitigator = QDTErrorMitigator()\n",
    "mitigator.prepare_mitigator(ml_povm_estimator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After those preparations, we can now check how our error mitigation approach works. Let's consider two simple scenarios."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### X gate circuit\n",
    "\n",
    "In this case, we will first create a one qubit circuit (initially in |0><0| state) and we will apply X (not) operation\n",
    "to it. In ideal scenario we would expect only counts in state '1'. We begin with circuit creation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In order to check how efficient our mitigator is, we need to obtain some noisy data first.\n",
    "# We will start with preparing simple experiment.\n",
    "\n",
    "qr = QuantumRegister(1, 'qreg')\n",
    "cr = ClassicalRegister(1, 'creg')\n",
    "qc = QuantumCircuit(qr, cr)\n",
    "\n",
    "qc.x(qr[0])\n",
    "qc.measure(qr, cr);\n",
    "\n",
    "shots_number = 8192"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we execute this circuit on our simulator and check the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.035 0.965]\n"
     ]
    }
   ],
   "source": [
    "result = execute(qc, simulator_backend, coupling_map=coupling_map, basis_gates=basis_gates,\n",
    "                 noise_model=noise_model, shots=shots_number)\\\n",
    "                 .result()\n",
    "\n",
    "for i in range(len(result.results)):\n",
    "    counts_now = result.get_counts(i)\n",
    "    frequencies_now = povmtools.counts_dict_to_frequencies_vector(counts_now)\n",
    "    print(np.round(frequencies_now,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, noisy simulator returned some errors ('0' counts), as expected. Let's try to correct these results using\n",
    "our mitigator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.]\n",
      " [1.]]\n"
     ]
    }
   ],
   "source": [
    "# Now let's correct them.\n",
    "corrected_results = mitigator.apply_correction_to_qiskit_job(result)\n",
    "print(np.round(corrected_results[0],3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### H gate circuit\n",
    "\n",
    "Now we will use H (Hadamard) gate. Everything else will be exactly like in the first scenario. We begin with creating\n",
    "and executing a circuit and then printing raw results of the job. We expect to obtain equal number of '0' and '1'\n",
    "counts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.486 0.514]\n"
     ]
    }
   ],
   "source": [
    "# Let's try another example.\n",
    "qr2 = QuantumRegister(1, 'qreg2')\n",
    "cr2 = ClassicalRegister(1, 'creg2')\n",
    "qc2 = QuantumCircuit(qr2, cr2)\n",
    "\n",
    "qc2.h(qr2[0])\n",
    "qc2.measure(qr2, cr2)\n",
    "\n",
    "result = execute(qc2, simulator_backend, coupling_map=coupling_map, basis_gates=basis_gates,\n",
    "                 noise_model=noise_model, shots=shots_number)\\\n",
    "                 .result()\n",
    "\n",
    "for i in range(len(result.results)):\n",
    "    counts_now = result.get_counts(i)\n",
    "    frequencies_now = povmtools.counts_dict_to_frequencies_vector(counts_now)\n",
    "    print(np.round(frequencies_now,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that again have distribution which is not perfect. Let's apply error mitigation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.502]\n",
      " [0.498]]\n"
     ]
    }
   ],
   "source": [
    "# Now let's correct them.\n",
    "corrected_results = mitigator.apply_correction_to_qiskit_job(result)\n",
    "print(np.round(corrected_results[0],3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once again, the results are better!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Errors in mitigation\n",
    "In the above benchmark experiments it was straightforward to assess the effectiveness of mitigation - since we knew the\n",
    "theoretical distributions, we could simply compare the corrected statistics to this distribution.\n",
    "\n",
    "In realistic scenarios, however, if one does not know what is the underlying ideal distribution, it is impossible to\n",
    "assess the success of mitigation. However, following procedure described in [[1]](https://quantum-journal.org/papers/q-2020-04-24-257/), we can heuristically asses if it is\n",
    "likely that mitigation succeeded (see theoretical background of this tutorial).\n",
    "\n",
    "We start with calculating statistical error bound. We start with setting mistake probability (in theoretical background\n",
    "denoted as $\\text{Pr}_{\\text{wrong}}$)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "statistical_error_mistake_probability = 0.01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need counts formatted as list or array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need counts as array. The outcomes are 0 or 1, so we can create them in straightforward way.\n",
    "counts_dict = result.get_counts()\n",
    "counts_list = [counts_dict['0'], counts_dict['1']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can use povmtools method to calculate statistical error bound."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "statistical errors: 0.017982870414073163\n"
     ]
    }
   ],
   "source": [
    "# We calculate statistical error bound. Let's call it epsilon.\n",
    "epsilon = povmtools.get_statistical_error_bound(counts_list, statistical_error_mistake_probability)\n",
    "print('statistical errors:',epsilon)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now need bound for possible errors in our mitigation. Luckily, we have all the arguments necessary for its\n",
    "calculation using prepared povmtools method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unphysicality error: 0\n",
      "total mitigation error: 0.021626910856366803\n"
     ]
    }
   ],
   "source": [
    "#get correction matrix\n",
    "correction_matrix = mitigator.correction_matrix\n",
    "\n",
    "\n",
    "#do not forget about possible term from unphysicality. \n",
    "alpha = mitigator.distances_from_closest_probability_vector[0]\n",
    "print('unphysicality error:',alpha)\n",
    "\n",
    "\n",
    "\n",
    "# We now need the correction error bound. \n",
    "mitigation_error = povmtools.get_correction_error_bound_from_data_and_statistical_error(ml_povm_estimator,\n",
    "                                                                             correction_matrix, \n",
    "                                                                             epsilon,\n",
    "                                                                             alpha)\n",
    "\n",
    "\n",
    "print('total mitigation error:',mitigation_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that since we took a classical noise model from IBM's backend properties, the above error arises solely due to\n",
    "statistical fluctuations and might be underestimated since it does not account for possible coherent errors.\n",
    "\n",
    "Last thing required for determining mitigation success is operational distance between perfect measurement and our\n",
    "ml_povm_estimator. We calculate it using povmtools module function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "errors without mitigation: 0.07049924108320117\n"
     ]
    }
   ],
   "source": [
    "# We also need operational distance, between perfect detector and our POVM. We calculate it.\n",
    "perfect_measurement = povmtools.computational_projectors(d=2) # For one qubit!\n",
    "operational_distance = povmtools.operational_distance_POVMs(ml_povm_estimator, perfect_measurement)\n",
    "print('errors without mitigation:',operational_distance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And finally, we can check if our criterion for assesing success of the mitigation works in this case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mitigation successful: True\n"
     ]
    }
   ],
   "source": [
    "# Now we can check if mitigation can be considered successful\n",
    "print(f'Mitigation successful: {mitigation_error < operational_distance + epsilon}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi Qubit error mitigation scenario\n",
    "\n",
    "Our method can easily be expanded for multiple qubits. It's done analogically to the single qubit experiments. We start\n",
    "with preparing noisy backend. We can use the same code as in one qubit scenario."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ibmqfactory.load_account:WARNING:2020-05-06 05:08:30,952: Credentials are already in use. The existing account in the session will be replaced.\n"
     ]
    }
   ],
   "source": [
    "from qiskit import QuantumCircuit, ClassicalRegister, QuantumRegister\n",
    "from qiskit import execute\n",
    "from qiskit import IBMQ, Aer\n",
    "from qiskit.providers.aer.noise import NoiseModel\n",
    "\n",
    "import povmtools\n",
    "from DetectorTomography import DetectorTomographyFitter, QDTCalibrationSetup\n",
    "from quantum_tomography_qiskit import detector_tomography_circuits\n",
    "from QDTErrorMitigator import QDTErrorMitigator\n",
    "\n",
    "#  What I want to have first is working noisy backend simulation. In order to do that, I will use qiskit noise model\n",
    "# and download properties of selected backend.\n",
    "\n",
    "# Build noise model from backend properties.\n",
    "provider = IBMQ.load_account()\n",
    "backend = provider.get_backend('ibmq_burlington')\n",
    "noise_model = NoiseModel.from_backend(backend)\n",
    "\n",
    "# Get coupling map from backend, why not.\n",
    "coupling_map = backend.configuration().coupling_map\n",
    "\n",
    "# Get basis gates from noise model.\n",
    "basis_gates = noise_model.basis_gates\n",
    "\n",
    "# Finally, get the simulator backend.\n",
    "simulator_backend = Aer.get_backend('qasm_simulator')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the POVM. This time we need higher dimensional one, as we are considering multi qubit scenario. The code, however,\n",
    "doesn't change much. The only thing we need to do is to modify qdt_qubit_indices list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.855 0.065 0.075 0.006]\n",
      "[0.108 0.008 0.823 0.062]\n",
      "[0.483 0.036 0.446 0.035]\n",
      "[0.48  0.036 0.449 0.034]\n",
      "[0.483 0.036 0.447 0.034]\n",
      "[0.484 0.036 0.447 0.034]\n",
      "[0.035 0.886 0.003 0.076]\n",
      "[0.005 0.112 0.034 0.85 ]\n",
      "[0.02  0.499 0.018 0.462]\n",
      "[0.019 0.496 0.018 0.467]\n",
      "[0.019 0.496 0.019 0.466]\n",
      "[0.02  0.497 0.019 0.465]\n",
      "[0.444 0.476 0.038 0.042]\n",
      "[0.055 0.059 0.431 0.456]\n",
      "[0.249 0.267 0.234 0.251]\n",
      "[0.249 0.267 0.234 0.25 ]\n",
      "[0.252 0.265 0.234 0.248]\n",
      "[0.249 0.269 0.235 0.247]\n",
      "[0.446 0.473 0.039 0.042]\n",
      "[0.056 0.059 0.428 0.457]\n",
      "[0.249 0.266 0.234 0.25 ]\n",
      "[0.25  0.265 0.234 0.252]\n",
      "[0.252 0.267 0.232 0.249]\n",
      "[0.251 0.268 0.233 0.248]\n",
      "[0.444 0.476 0.038 0.042]\n",
      "[0.057 0.061 0.427 0.455]\n",
      "[0.251 0.268 0.234 0.247]\n",
      "[0.251 0.267 0.232 0.25 ]\n",
      "[0.25  0.267 0.235 0.248]\n",
      "[0.251 0.268 0.233 0.247]\n",
      "[0.445 0.475 0.039 0.041]\n",
      "[0.057 0.059 0.427 0.457]\n",
      "[0.25  0.268 0.234 0.248]\n",
      "[0.25  0.268 0.232 0.25 ]\n",
      "[0.249 0.267 0.234 0.249]\n",
      "[0.252 0.267 0.232 0.248]\n"
     ]
    }
   ],
   "source": [
    "# What we want to do now, is prepare POVM for simulated backend. According to our other notebook, we prepare\n",
    "# circuits first.\n",
    "\n",
    "qdt_qubit_indices = [0, 1]\n",
    "qdt_probe_kets = povmtools.pauli_probe_eigenkets\n",
    "qdt_calibration_circuits = detector_tomography_circuits(qdt_qubit_indices, qdt_probe_kets)\n",
    "\n",
    "# We then execute them on backend prepared earlier.\n",
    "shots_number = 8192*20\n",
    "\n",
    "# Perform a noisy simulation\n",
    "result = execute(qdt_calibration_circuits, simulator_backend, coupling_map=coupling_map, basis_gates=basis_gates,\n",
    "                 noise_model=noise_model, shots=shots_number) \\\n",
    "    .result()\n",
    "\n",
    "# Print counts.\n",
    "for i in range(len(result.results)):\n",
    "    counts_now = result.get_counts(i)\n",
    "    frequencies_now = povmtools.counts_dict_to_frequencies_vector(counts_now)\n",
    "    print(np.round(frequencies_now,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can calculate the POVM estimator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              0             1             2             3\n",
      "0  0.855-0.000j -0.000+0.000j -0.001-0.000j -0.000-0.000j\n",
      "1 -0.000-0.000j  0.108-0.000j  0.001+0.000j -0.000-0.000j\n",
      "2 -0.001+0.000j  0.001-0.000j  0.035+0.000j  0.000+0.000j\n",
      "3 -0.000+0.000j -0.000+0.000j  0.000-0.000j  0.005-0.000j \n",
      "\n",
      "              0             1             2             3\n",
      "0  0.074+0.000j  0.000-0.000j -0.000+0.000j -0.000-0.000j\n",
      "1  0.000+0.000j  0.822-0.000j -0.000+0.000j  0.001-0.000j\n",
      "2 -0.000-0.000j -0.000-0.000j  0.003+0.000j  0.000-0.000j\n",
      "3 -0.000+0.000j  0.001+0.000j  0.000+0.000j  0.034-0.000j \n",
      "\n",
      "              0             1             2             3\n",
      "0  0.065-0.000j -0.000-0.000j  0.001+0.000j -0.000+0.000j\n",
      "1 -0.000+0.000j  0.008+0.000j -0.001-0.001j -0.000-0.001j\n",
      "2  0.001-0.000j -0.001+0.001j  0.885+0.000j  0.001+0.001j\n",
      "3 -0.000-0.000j -0.000+0.001j  0.001-0.001j  0.111-0.000j \n",
      "\n",
      "             0             1             2             3\n",
      "0 0.006-0.000j  0.000+0.000j  0.000-0.001j  0.001-0.000j\n",
      "1 0.000-0.000j  0.062+0.000j  0.001+0.000j -0.000+0.001j\n",
      "2 0.000+0.001j  0.001-0.000j  0.077+0.000j -0.001-0.001j\n",
      "3 0.001+0.000j -0.000-0.001j -0.001+0.001j  0.850+0.000j \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# With circuits results we can now use our Detector Tomography Fitter to obtain maximum likelihood POVM estimator.\n",
    "dtf = DetectorTomographyFitter()\n",
    "calibration_setup = QDTCalibrationSetup.from_qiskit_results([result], qdt_probe_kets)\n",
    "ml_povm_estimator = dtf.get_maximum_likelihood_povm_estimator(calibration_setup)\n",
    "\n",
    "for m_i in ml_povm_estimator:\n",
    "    nice_looking_m_i = pd.DataFrame(m_i)\n",
    "    print(nice_looking_m_i,'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And with POVM estimator, we can prepare mitigator object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can use obtained POVM to correct to prepare mitigation object.\n",
    "mitigator = QDTErrorMitigator()\n",
    "mitigator.prepare_mitigator(ml_povm_estimator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, let's check how the mitigation works on several circuits."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hadamards circuit\n",
    "\n",
    "We begin with circuit applying Hadamard gates on both qubits. Let's prepare such circuit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In order to check how efficient our mitigator is, we need to obtain some noisy data first.\n",
    "# We will start with preparing simple experiment.\n",
    "\n",
    "qr = QuantumRegister(2, 'qreg')\n",
    "cr = ClassicalRegister(2, 'creg')\n",
    "qc = QuantumCircuit(qr, cr)\n",
    "\n",
    "qc.h(qr[0])\n",
    "qc.h(qr[1])\n",
    "qc.measure(qr, cr);\n",
    "shots_number = 8192"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then execute this circuit and print the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.2498779296875, 0.2681884765625, 0.22900390625, 0.2529296875]\n"
     ]
    }
   ],
   "source": [
    "result = execute(qc, simulator_backend, coupling_map=coupling_map, basis_gates=basis_gates,\n",
    "                 noise_model=noise_model, shots=shots_number) \\\n",
    "    .result()\n",
    "\n",
    "for i in range(len(result.results)):\n",
    "    counts_now = result.get_counts(i)\n",
    "    frequencies_now = povmtools.counts_dict_to_frequencies_vector(counts_now)\n",
    "    print(frequencies_now)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.24975155]\n",
      " [0.24451221]\n",
      " [0.25062017]\n",
      " [0.25511607]]\n"
     ]
    }
   ],
   "source": [
    "corrected_results = mitigator.apply_correction_to_qiskit_job(result)\n",
    "\n",
    "print(corrected_results[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At the first glance the results are corrected, however in this case it is hard to say \"by eye\" how significantly. Let's calculate Total-Variation Distance from ideal distributions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distance before correction: 0.0211181640625\n",
      "Distance before correction: 0.005736241155083366\n"
     ]
    }
   ],
   "source": [
    "ideal_distribution = np.array([1/4 for i in range(4)]).reshape(4,1)\n",
    "corrected_results = corrected_results[0]\n",
    "noisy_results = np.array(frequencies_now).reshape(4,1)\n",
    "\n",
    "distance_noisy = 1/2*np.linalg.norm(ideal_distribution-noisy_results,ord=1)\n",
    "distance_corrected = 1/2*np.linalg.norm(ideal_distribution-corrected_results,ord=1)\n",
    "\n",
    "print('Distance before correction:',distance_noisy)\n",
    "print('Distance before correction:',distance_corrected)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As inditcated in theoretical background, errors in mitigation can come either from coherent noise, either from statistical fluctuations. Let us perform the same experiments for higher number of samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distance before correction: 0.0177001953125\n",
      "Distance before correction: 0.0008256529399654766\n"
     ]
    }
   ],
   "source": [
    "# In order to check how efficient our mitigator is, we need to obtain some noisy data first.\n",
    "# We will start with preparing simple experiment.\n",
    "\n",
    "qr = QuantumRegister(2, 'qreg')\n",
    "cr = ClassicalRegister(2, 'creg')\n",
    "qc = QuantumCircuit(qr, cr)\n",
    "\n",
    "qc.h(qr[0])\n",
    "qc.h(qr[1])\n",
    "qc.measure(qr, cr);\n",
    "shots_number = 8192*10\n",
    "\n",
    "result = execute(qc, simulator_backend, coupling_map=coupling_map, basis_gates=basis_gates,\n",
    "                 noise_model=noise_model, shots=shots_number) \\\n",
    "    .result()\n",
    "\n",
    "for i in range(len(result.results)):\n",
    "    counts_now = result.get_counts(i)\n",
    "    frequencies_now = povmtools.counts_dict_to_frequencies_vector(counts_now)\n",
    "    \n",
    "corrected_results = mitigator.apply_correction_to_qiskit_job(result)\n",
    "\n",
    "ideal_distribution = np.array([1/4 for i in range(4)]).reshape(4,1)\n",
    "corrected_results = corrected_results[0]\n",
    "noisy_results = np.array(frequencies_now).reshape(4,1)\n",
    "\n",
    "distance_noisy = 1/2*np.linalg.norm(ideal_distribution-noisy_results,ord=1)\n",
    "distance_corrected = 1/2*np.linalg.norm(ideal_distribution-corrected_results,ord=1)\n",
    "\n",
    "print('Distance before correction:',distance_noisy)\n",
    "print('Distance before correction:',distance_corrected)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that now correction is much more significant! This is an important observation, since the \"blind\" application of such mitigation scheme for low-sample statistics may lead to relatively small improvement, and in extreme cases to actually worse results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's try mitigation with some multi-qubit gates."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNOT Circuit\n",
    "\n",
    "This time we will use a CNOT gate. First we will prepare a qubit in state |1> and then use it as a control to negate the\n",
    "other qubit. We expect all counts to be in state '11'. The circuit can be codded as below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's try another example.\n",
    "qr2 = QuantumRegister(2, 'qreg2')\n",
    "cr2 = ClassicalRegister(2, 'creg2')\n",
    "qc2 = QuantumCircuit(qr2, cr2)\n",
    "\n",
    "qc2.x(qr2[0])\n",
    "qc2.cx(qr2[0], qr2[1])\n",
    "qc2.measure(qr2, cr2);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Executing this circuits yields following results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.00703125, 0.11336669921875, 0.03553466796875, 0.8440673828125]\n"
     ]
    }
   ],
   "source": [
    "result = execute(qc2, simulator_backend, coupling_map=coupling_map, basis_gates=basis_gates,\n",
    "                 noise_model=noise_model, shots=shots_number) \\\n",
    "    .result()\n",
    "\n",
    "for i in range(len(result.results)):\n",
    "    counts_now = result.get_counts(i)\n",
    "    frequencies_now = povmtools.counts_dict_to_frequencies_vector(counts_now)\n",
    "    print(frequencies_now)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected, we can see some erroneous results. Let's try to mitigate it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.003]\n",
      " [0.002]\n",
      " [0.003]\n",
      " [0.992]]\n"
     ]
    }
   ],
   "source": [
    "# Now let's correct them.\n",
    "corrected_results = mitigator.apply_correction_to_qiskit_job(result)\n",
    "print(np.round(corrected_results[0],3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Easily enough, the results are clearly better. Let's now combine Hadamard and CNOT gate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hadamard + CNOT circuit\n",
    "\n",
    "In this scenario, we will first prepare first qubit in superposition of states |0> and |1>. We will then, again, use it\n",
    "as a control qubit to negate the second one. We will expect equal number of counts in '00' and '11' states. The circuit\n",
    "can be prepared like below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final example!\n",
    "qr3 = QuantumRegister(2, 'qreg2')\n",
    "cr3 = ClassicalRegister(2, 'creg2')\n",
    "qc3 = QuantumCircuit(qr3, cr3)\n",
    "\n",
    "qc3.h(qr3[0])\n",
    "qc3.cx(qr3[0], qr2[1])\n",
    "qc3.measure(qr3, cr3);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now execute it and print the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.42880859375, 0.08980712890625, 0.05550537109375, 0.42587890625]\n"
     ]
    }
   ],
   "source": [
    "result = execute(qc3, simulator_backend, coupling_map=coupling_map, basis_gates=basis_gates,\n",
    "                 noise_model=noise_model, shots=shots_number) \\\n",
    "    .result()\n",
    "\n",
    "for i in range(len(result.results)):\n",
    "    counts_now = result.get_counts(i)\n",
    "    frequencies_now = povmtools.counts_dict_to_frequencies_vector(counts_now)\n",
    "    print(frequencies_now)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There's some room for improvement. Let's apply the mitigation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.498]\n",
      " [0.002]\n",
      " [0.003]\n",
      " [0.497]]\n"
     ]
    }
   ],
   "source": [
    "# Now let's correct them.\n",
    "corrected_results = mitigator.apply_correction_to_qiskit_job(result)\n",
    "print(np.round(corrected_results[0],3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once again, the results are clearly better.\n",
    "\n",
    "In the benchmark experiments presented above, it was straitghtforward to determine if the mitigation worked - either by looking at the results, either by calculating distance from ideal distribution (two Hadamards example). \n",
    "\n",
    "In realistic scenario, where ideal distribution are not known, one should refer to the heuristic criterion of assessing mitigation success, which was discussed above in single-qubit example. \n",
    "\n",
    "For the sake of completness, let us now perform similar checks for the multi-qubit experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "statistical errors: 0.00664945530344704\n",
      "unphysicality error: 0\n",
      "total mitigation error: 0.01405437031313742\n"
     ]
    }
   ],
   "source": [
    "# We need counts as array. The outcomes are 0 or 1, so we can create them in straightforward way.\n",
    "counts_dict = result.get_counts()\n",
    "counts_list = np.array(povmtools.counts_dict_to_frequencies_vector(counts_dict))*shots_number\n",
    "\n",
    "\n",
    "# We calculate statistical error bound. \n",
    "epsilon = povmtools.get_statistical_error_bound(counts_list, statistical_error_mistake_probability)\n",
    "print('statistical errors:',epsilon)\n",
    "\n",
    "\n",
    "\n",
    "#get correction matrix\n",
    "correction_matrix = mitigator.correction_matrix\n",
    "\n",
    "\n",
    "#do not forget about possible term from unphysicality. \n",
    "alpha = mitigator.distances_from_closest_probability_vector[0]\n",
    "print('unphysicality error:',alpha)\n",
    "\n",
    "\n",
    "\n",
    "# We now need the correction error bound.\n",
    "mitigation_error = povmtools.get_correction_error_bound_from_data_and_statistical_error(ml_povm_estimator,\n",
    "                                                                             correction_matrix, \n",
    "                                                                             epsilon,\n",
    "                                                                             alpha)\n",
    "\n",
    "\n",
    "print('total mitigation error:',mitigation_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall once again that since we took a classical noise model from IBM's backend properties, the above error arises\n",
    "solely due to statistical fluctuations and might be underestimated since it does not account for coherent errors. Furthermore, errors are assumed to be uncorrelated, which also might underestimate their magnitude.\n",
    "\n",
    "Note that mitigation error is higher than in case of single-qubit experiments. This is due to the fact that sampling\n",
    "complexity is higher for 4-dimensional probability distributions. However, we expect that also errors without mitigation\n",
    "increase:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "errors without mitigation: 0.17792666738731278\n",
      "Mitigation successful: True\n"
     ]
    }
   ],
   "source": [
    "# We need operational distance between perfect detector and our POVM. We calculate it.\n",
    "perfect_measurement = povmtools.computational_projectors(d=4) # For two qubits\n",
    "operational_distance = povmtools.operational_distance_POVMs(ml_povm_estimator, perfect_measurement)\n",
    "print('errors without mitigation:',operational_distance)\n",
    "\n",
    "# Now we can check if mitigation can be considered successful\n",
    "print(f'Mitigation successful: {mitigation_error < operational_distance + epsilon}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References\n",
    "\n",
    "[1] Maciejewski B. F., Zimboras Z., Oszmaniec M.,\n",
    "[Mitigation of readout noise in near-term quantum devices by classical post-processing based on detector tomography](https://quantum-journal.org/papers/q-2020-04-24-257/), Quantum 4, 257.\n",
    "\n",
    "[2] Hradil Z., Rehacek J., Fiurasek J. and Jezek M., __3 maximum-likelihood methods in quantum mechanics__, Quantum\n",
    "State Estimation (Paris M., Rehacek J. eds) pp.59-112, Springer, Berlin, 2004."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
